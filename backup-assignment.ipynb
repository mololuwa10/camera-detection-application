{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d608b1b0-2ea8-4fc2-a993-48c980f3554b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No file selected\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk, filedialog, messagebox\n",
    "import cv2\n",
    "from PIL import Image, ImageTk\n",
    "import numpy as np \n",
    "import threading\n",
    "from queue import Queue\n",
    "from datetime import datetime\n",
    "import json\n",
    "import imutils\n",
    "import os\n",
    "import inspect\n",
    "\n",
    "def load_calibration_data():\n",
    "    # Function to load calibration data\n",
    "    calibration_file_path = filedialog.askopenfilename(title=\"Select Calibration Data File\", filetypes=[(\"JSON files\", \"*.json\")])\n",
    "    if not calibration_file_path:\n",
    "        print(\"No file selected\")\n",
    "        return None, None\n",
    "\n",
    "    try:\n",
    "        with open(calibration_file_path, 'r') as f:\n",
    "            calibration_data = json.load(f)\n",
    "        camera_matrix = np.array(calibration_data['camera_matrix'])\n",
    "        distortion_coeffs = np.array(calibration_data['distortion_coefficients'])\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading calibration data: {e}\")\n",
    "        return None, None\n",
    "\n",
    "    return camera_matrix, distortion_coeffs\n",
    "\n",
    "\n",
    "class ObjectDetectionGUI:\n",
    "    def __init__(self, window, window_title):\n",
    "        self.window = window\n",
    "        self.window.title(window_title)\n",
    "\n",
    "        # Style configuration\n",
    "        self.style = ttk.Style()\n",
    "        self.style.theme_use('default')\n",
    "\n",
    "        # Main frame\n",
    "        main_frame = ttk.Frame(window)\n",
    "        main_frame.pack(fill=tk.BOTH, expand=True)\n",
    "        \n",
    "        # Create a canvas that can fit the above video source size\n",
    "        self.canvas = tk.Canvas(window, width=800, height=600)\n",
    "        self.canvas.pack(side=tk.TOP, fill=tk.BOTH, expand=True)\n",
    "\n",
    "        # Control frame\n",
    "        control_frame = ttk.Frame(main_frame)\n",
    "        control_frame.pack(side=tk.BOTTOM, fill=tk.X)\n",
    "\n",
    "        # Buttons to control playback\n",
    "        self.btn_select = tk.Button(control_frame, text=\"Select Video\", width=15, command=self.open_file)\n",
    "        self.btn_select.pack(side=tk.LEFT, padx=5, pady=5)\n",
    "\n",
    "        self.btn_play = tk.Button(control_frame, text=\"Play\", width=15, command=self.play_video)\n",
    "        self.btn_play.pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        # Additional buttons for Pause, Resume, Stop, and Capture Frame\n",
    "        self.btn_pause = tk.Button(control_frame, text=\"Pause\", width=15, command=self.pause_video)\n",
    "        self.btn_pause.pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        self.btn_resume = tk.Button(control_frame, text=\"Resume\", width=15, command=self.resume_video)\n",
    "        self.btn_resume.pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        self.btn_stop = tk.Button(control_frame, text=\"Stop\", width=15, command=self.stop_video)\n",
    "        self.btn_stop.pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        self.btn_capture = tk.Button(control_frame, text=\"Capture Frame\", width=15, command=self.capture_frame)\n",
    "        self.btn_capture.pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        self.btn_live = tk.Button(control_frame, text=\"Live Feed\", width=15, command=self.start_live_feed)\n",
    "        self.btn_live.pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "        # Button for selecting images for stitching\n",
    "        self.btn_stitch_select = tk.Button(control_frame, text=\"Select Images for Stitching\", width=20, command=self.select_images_for_stitching)\n",
    "        self.btn_stitch_select.pack(side=tk.LEFT, padx=5, pady=5)\n",
    "    \n",
    "        # Button to stitch images\n",
    "        self.btn_stitch = tk.Button(control_frame, text=\"Stitch Images\", width=15, command=self.stitch_images)\n",
    "        self.btn_stitch.pack(side=tk.LEFT, padx=5, pady=5)\n",
    "\n",
    "        # Add a button for testing distortion correction\n",
    "        self.btn_test_distortion = tk.Button(control_frame, text=\"Test Distortion Correction\", width=25, command=self.test_distortion_correction)\n",
    "        self.btn_test_distortion.pack(side=tk.LEFT, padx=5, pady=5)\n",
    "\n",
    "        # Additional instance variables to manage playback state\n",
    "        self.paused = False\n",
    "        self.stopped = False\n",
    "\n",
    "        self.delay = 15 \n",
    "        self.video_source = None\n",
    "        self.vid = None\n",
    "\n",
    "        # List to store selected image paths\n",
    "        self.stitching_images = []\n",
    "\n",
    "    def select_images_for_stitching(self):\n",
    "        self.stitching_images = filedialog.askopenfilenames()\n",
    "\n",
    "    def stitch_images(self):\n",
    "        # Convert image paths to OpenCV images\n",
    "        images = [cv2.imread(image_path) for image_path in self.stitching_images]\n",
    "\n",
    "        # Check if there are at least two images\n",
    "        if len(images) < 2:\n",
    "            print(\"Need at least two images to stitch\")\n",
    "            return\n",
    "\n",
    "        # Create a stitcher object and stitch the images\n",
    "        stitcher = cv2.createStitcher() if imutils.is_cv3() else cv2.Stitcher_create()\n",
    "        status, stitched = stitcher.stitch(images)\n",
    "\n",
    "        if status == 0:  # Check if the stitching is successful\n",
    "            # Display the stitched image or save it\n",
    "            self.display_stitched_image(stitched)\n",
    "        else:\n",
    "            messagebox.showerror(\"Stitching failed. Status code:\", status)\n",
    "\n",
    "    def display_stitched_image(self, stitched_image):\n",
    "        # Calculate the new size, maintaining aspect ratio\n",
    "        canvas_width = self.canvas.winfo_width()\n",
    "        canvas_height = self.canvas.winfo_height()\n",
    "        original_height, original_width = stitched_image.shape[:2]\n",
    "        \n",
    "        # Calculate the aspect ratio of image and canvas\n",
    "        image_aspect = original_width / original_height\n",
    "        canvas_aspect = canvas_width / canvas_height\n",
    "        \n",
    "        # Determine the appropriate resize scaling factor\n",
    "        if image_aspect > canvas_aspect:\n",
    "            # Image is wider than the canvas, so scale by width\n",
    "            new_width = canvas_width\n",
    "            new_height = int(canvas_width / image_aspect)\n",
    "        else:\n",
    "            # Image is taller than the canvas, so scale by height\n",
    "            new_height = canvas_height\n",
    "            new_width = int(canvas_height * image_aspect)\n",
    "        \n",
    "        # Resize the image using the new width and height\n",
    "        resized_image = cv2.resize(stitched_image, (new_width, new_height), interpolation=cv2.INTER_AREA)\n",
    "        \n",
    "        # Convert the resized image for Tkinter and display it\n",
    "        im_pil = Image.fromarray(cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB))\n",
    "        imgtk = ImageTk.PhotoImage(image=im_pil)\n",
    "        \n",
    "        # Update the canvas with the new image\n",
    "        self.canvas.create_image(0, 0, anchor=\"nw\", image=imgtk)\n",
    "        self.canvas.image = imgtk  \n",
    "\n",
    "    def pause_video(self):\n",
    "        self.paused = True\n",
    "\n",
    "    def resume_video(self):\n",
    "        self.paused = False\n",
    "        self.play_video()\n",
    "\n",
    "    def stop_video(self):\n",
    "        self.stopped = True\n",
    "        if self.vid:\n",
    "            self.vid.release()\n",
    "        self.vid = None\n",
    "        self.canvas.delete(\"all\")\n",
    "        \n",
    "    def capture_frame(self):\n",
    "        if not self.vid:\n",
    "            return\n",
    "        ret, frame = self.vid.get_frame()\n",
    "        if ret:\n",
    "            # Get the current timestamp and format it to create a unique filename\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S%f\")\n",
    "            filename = f\"captured_frame_{timestamp}.png\"\n",
    "            # Save the captured frame to a file with the unique filename\n",
    "            cv2.imwrite(filename, frame)\n",
    "\n",
    "    def start_live_feed(self):\n",
    "        # Stop any existing video playback\n",
    "        self.stop_video()\n",
    "        self.paused = False\n",
    "        self.stopped = False\n",
    "\n",
    "        # Release previous video source\n",
    "        if self.vid:\n",
    "            self.vid.release()\n",
    "            self.vid = None\n",
    "\n",
    "        # Open live video source\n",
    "        self.vid = MyVideoCapture(0)\n",
    "\n",
    "        # Clear the canvas\n",
    "        self.canvas.delete(\"all\")\n",
    "\n",
    "        # Start displaying the live feed\n",
    "        self.play_video()\n",
    "\n",
    "        # Start the video capture and detection thread\n",
    "        self.detection_thread = threading.Thread(target=self.vid.get_frame)\n",
    "        self.detection_thread.daemon = True\n",
    "        self.detection_thread.start()\n",
    "\n",
    "    def open_file(self):\n",
    "        # Release the previous video capture object if it exists\n",
    "        self.stop_video()\n",
    "        self.paused = False\n",
    "        self.stopped = False\n",
    "        \n",
    "        self.video_source = filedialog.askopenfilename()\n",
    "        if self.video_source: # If a file is selected, create a new video capture object\n",
    "            self.vid = MyVideoCapture(self.video_source)\n",
    "            self.play_video()\n",
    "\n",
    "    def play_video(self):\n",
    "        if self.stopped or not self.vid:\n",
    "            return\n",
    "            \n",
    "        if self.paused:\n",
    "            return\n",
    "        ret, frame = self.vid.get_frame()\n",
    "        if ret:\n",
    "            self.photo = ImageTk.PhotoImage(image=Image.fromarray(frame))\n",
    "            self.canvas.create_image(0, 0, image=self.photo, anchor=tk.NW)\n",
    "        # Schedule the next frame update\n",
    "        self.window.after(self.delay, self.play_video) \n",
    "\n",
    "    def test_distortion_correction(self):\n",
    "        if not self.vid:\n",
    "            messagebox.showerror(\"Error\", \"Video source not initialized\")\n",
    "            return\n",
    "    \n",
    "        ret, frame = self.vid.get_frame()\n",
    "        if ret:\n",
    "            # Show the original image in a new window\n",
    "            cv2.imshow('Original Image', frame)\n",
    "    \n",
    "            # Apply distortion correction if calibration data is available in MyVideoCapture\n",
    "            if self.vid.camera_matrix is not None and self.vid.distortion_coeffs is not None:\n",
    "                corrected_frame = cv2.undistort(frame, self.vid.camera_matrix, self.vid.distortion_coeffs, None)\n",
    "                # Show the corrected image in a new window\n",
    "                cv2.imshow('Corrected Image', corrected_frame)\n",
    "            else:\n",
    "                messagebox.showinfo(\"Info\", \"Calibration data not found, showing original image only.\")\n",
    "    \n",
    "            # Wait for a key press to close the windows\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "        else:\n",
    "            messagebox.showerror(\"Error\", \"Failed to capture frame from video source\")\n",
    "\n",
    "class MyVideoCapture:\n",
    "    def __init__(self, video_source):\n",
    "        # Open the video source\n",
    "        self.vid = cv2.VideoCapture(video_source)\n",
    "        if not self.vid.isOpened():\n",
    "            raise ValueError(\"Unable to open video source\", video_source)\n",
    "\n",
    "        self.frame_rate = self.vid.get(cv2.CAP_PROP_FPS)\n",
    "        self.frame_time = 1 / self.frame_rate if self.frame_rate > 0 else 1 / 30 \n",
    "\n",
    "        # Get video source width and height\n",
    "        self.width = self.vid.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "        self.height = self.vid.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "\n",
    "        # Loading YOLO for object detection\n",
    "        self.net = cv2.dnn.readNet('yolov4-tiny.weights', 'yolov4-tiny.cfg')\n",
    "        self.classes = []\n",
    "        with open(\"coco.names\", \"r\") as f:\n",
    "            self.classes = [line.strip() for line in f.readlines()]\n",
    "            \n",
    "        self.layer_names = self.net.getLayerNames()\n",
    "        self.output_layers = [self.layer_names[i - 1] for i in self.net.getUnconnectedOutLayers()]\n",
    "\n",
    "        self.positions = {} \n",
    "        self.previous_positions = {}\n",
    "        self.object_ids = {}  # Maps a unique ID to each object\n",
    "        self.next_object_id = 0  # Next ID to assign\n",
    "        self.speeds = {}  # To store speeds of objects\n",
    "        self.scale = 10\n",
    "        self.speed_threshold = 50  \n",
    "        self.movement_category = \"Unknown\"\n",
    "        self.annotations_list = []\n",
    "        self.frame_buffer = []\n",
    "        self.buffer_size = 30\n",
    "\n",
    "        # Load calibration data\n",
    "        self.camera_matrix, self.distortion_coeffs = load_calibration_data()\n",
    "           \n",
    "    def update_buffer(self, frame):\n",
    "        self.frame_buffer.append(frame)\n",
    "        if len(self.frame_buffer) > self.buffer_size:\n",
    "            self.frame_buffer.pop(0)\n",
    "\n",
    "    def save_segment(self, start_index, end_index, filename):\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "        out = cv2.VideoWriter(filename, fourcc, self.frame_rate, (int(self.width), int(self.height)))\n",
    "        for i in range(start_index, end_index):\n",
    "            out.write(self.frame_buffer[i])\n",
    "        out.release()\n",
    "\n",
    "    def compute_centroids(self, boxes):\n",
    "        return [(int(x + w / 2), int(y + h / 2)) for x, y, w, h in boxes]\n",
    "\n",
    "    def match_and_update_centroids(self, centroids):\n",
    "        MATCH_THRESHOLD = 100\n",
    "\n",
    "        # Update object_ids list to manage IDs\n",
    "        new_positions = {}\n",
    "        for centroid in centroids:\n",
    "            matched = False\n",
    "            for obj_id, position in self.previous_positions.items():\n",
    "                if np.linalg.norm(np.array(centroid) - np.array(position)) < MATCH_THRESHOLD:\n",
    "                    new_positions[obj_id] = centroid\n",
    "                    matched = True\n",
    "                    break\n",
    "            if not matched:\n",
    "                new_positions[self.next_object_id] = centroid\n",
    "                self.next_object_id += 1\n",
    "        self.positions = new_positions\n",
    "\n",
    "    def get_frame(self):\n",
    "        if self.vid.isOpened():\n",
    "            ret, frame = self.vid.read()\n",
    "            if ret:\n",
    "                # Apply distortion correction if calibration data is available\n",
    "                if self.camera_matrix is not None and self.distortion_coeffs is not None:\n",
    "                    frame = cv2.undistort(frame, self.camera_matrix, self.distortion_coeffs, None)\n",
    "                    \n",
    "                # Object Detection\n",
    "                blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "                self.net.setInput(blob)\n",
    "                outs = self.net.forward(self.output_layers)\n",
    "    \n",
    "                # Information to be returned\n",
    "                class_ids = []\n",
    "                confidences = []\n",
    "                boxes = []\n",
    "    \n",
    "                for out in outs:\n",
    "                    for detection in out:\n",
    "                        scores = detection[5:]\n",
    "                        class_id = np.argmax(scores)\n",
    "                        confidence = scores[class_id]\n",
    "                        # Validate frame dimensions and detection values\n",
    "                        if frame.shape[1] > 0 and all(0 <= v <= 1 for v in detection[:4]):\n",
    "                            try:\n",
    "                                center_x = int(detection[0] * frame.shape[1])\n",
    "                                center_y = int(detection[1] * frame.shape[0])\n",
    "                                w = int(detection[2] * frame.shape[1])\n",
    "                                h = int(detection[3] * frame.shape[0])\n",
    "                                x = int(center_x - w / 2)\n",
    "                                y = int(center_y - h / 2)\n",
    "        \n",
    "                                boxes.append([x, y, w, h])\n",
    "                                confidences.append(float(confidence))\n",
    "                                class_ids.append(class_id)\n",
    "                            except OverflowError as e:\n",
    "                                print(f\"Overflow error: {e}\")\n",
    "                                continue  # Skip this detection\n",
    "                        else:\n",
    "                            # print(f\"Invalid frame dimensions or detection values: {frame.shape}, {detection}\")\n",
    "                            continue \n",
    "    \n",
    "                indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "                centroids = self.compute_centroids([boxes[i] for i in indexes])\n",
    "                self.match_and_update_centroids(centroids)\n",
    "    \n",
    "                for i, index in enumerate(indexes):\n",
    "                    x, y, w, h = boxes[index]\n",
    "                    \n",
    "                    # Check if the index is within the bounds of the centroids list\n",
    "                    if i < len(centroids):\n",
    "                        centroid = centroids[i]\n",
    "                        matched_ids = [id for id, pos in self.positions.items() if pos == centroid]\n",
    "                        object_id = matched_ids[0] if matched_ids else -1\n",
    "                    # else:\n",
    "                    #     object_id = -1  # Placeholder for unmatched objects\n",
    "                \n",
    "                    label = str(self.classes[class_ids[index]])\n",
    "                    color = (0, 255, 0)\n",
    "                    # Ensure x, y, w, and h are integers\n",
    "                    x, y, w, h = int(x), int(y), int(w), int(h)\n",
    "                    cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
    "                    cv2.putText(frame, f'{label} {object_id}', (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
    "                \n",
    "                    self.calculate_and_display_speed(frame, object_id, centroid, x, y, w, h)\n",
    "    \n",
    "                self.previous_positions = self.positions.copy()\n",
    "                self.positions = {}\n",
    "                return (ret, cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "            else:\n",
    "                return (ret, None)\n",
    "        else:\n",
    "            return (False, None)\n",
    "\n",
    "    # Speed calculation\n",
    "    def calculate_and_display_speed(self, frame, object_id, centroid, x, y, w, h):\n",
    "        if object_id not in self.speeds:\n",
    "            self.speeds[object_id] = []\n",
    "            \n",
    "        if object_id in self.previous_positions:\n",
    "            # Calculate speed\n",
    "            speed = self.calculate_speed(centroid, object_id)\n",
    "            formatted_speed = \"{:.1f}\".format(speed)\n",
    "\n",
    "            # Display speed on the frame\n",
    "            speed_text = f\"{formatted_speed} km/h\"\n",
    "            text_position = (x, y - 10)  \n",
    "            if text_position[1] < 0: \n",
    "                text_position = (x, y + 20)\n",
    "    \n",
    "            cv2.putText(frame, speed_text, text_position, cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "            \n",
    "            # Determine movement category based on speed\n",
    "            self.movement_category = \"Speeding\" if speed > self.speed_threshold else \"Moving\" if speed > 10 else \"Stationary\"\n",
    "\n",
    "            # Speed threshold check and display\n",
    "            if speed > self.speed_threshold:\n",
    "                color = (0, 0, 255)  # Red color for over-speeding\n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h), color, 3)\n",
    "                self.log_and_save_speed_info(object_id, formatted_speed, frame)\n",
    "\n",
    "            # print(f\"Speed of object {object_id}: {formatted_speed} km/h, Category: {self.movement_category}\")\n",
    "\n",
    "        else:\n",
    "            # For new objects, just display them without speed calculation\n",
    "            color = (0, 255, 0)  # Green color for new objects\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
    "            \n",
    "        # Update previous positions\n",
    "        self.previous_positions = self.positions.copy()\n",
    "        self.positions[object_id] = centroid\n",
    "\n",
    "    def calculate_speed(self, centroid, object_id):\n",
    "        MAX_REALISTIC_SPEED = 300  # Maximum realistic speed in km/h\n",
    "        MOVING_AVERAGE_WINDOW = 5 \n",
    "        \n",
    "        if object_id in self.previous_positions:\n",
    "            # Calculate instantaneous speed\n",
    "            dx, dy = centroid[0] - self.previous_positions[object_id][0], centroid[1] - self.previous_positions[object_id][1]\n",
    "            distance_pixels = np.sqrt(dx ** 2 + dy ** 2)\n",
    "            distance_meters = distance_pixels / self.scale\n",
    "            instant_speed = (distance_meters / self.frame_time) * 3.6\n",
    "\n",
    "            if instant_speed > MAX_REALISTIC_SPEED:\n",
    "                instant_speed = 0  # Resetting unrealistic speed to 0\n",
    "\n",
    "            # Update the list of the speed for the object\n",
    "            if object_id not in self.speeds:\n",
    "                self.speeds[object_id] = []\n",
    "\n",
    "            self.speeds[object_id].append(instant_speed)\n",
    "\n",
    "            # Calculate moving average\n",
    "            if len(self.speeds[object_id]) > MOVING_AVERAGE_WINDOW:\n",
    "                self.speeds[object_id].pop(0) \n",
    "\n",
    "            avg_speed = sum(self.speeds[object_id]) / len(self.speeds[object_id])\n",
    "        else:\n",
    "            avg_speed = 0\n",
    "\n",
    "        return avg_speed\n",
    "\n",
    "    def log_and_save_speed_info(self, object_id, formatted_speed, frame):\n",
    "        annotation_info = {\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"object_type\": self.movement_category,\n",
    "            \"speed\": formatted_speed\n",
    "        }\n",
    "        self.annotations_list.append(annotation_info)\n",
    "        cv2.imwrite(f'annotated_frame_{object_id}.jpg', frame, [cv2.IMWRITE_JPEG_QUALITY, 90])\n",
    "\n",
    "        # Create JSON Annotation\n",
    "        json_data = self.create_json_annotation(object_id, formatted_speed, annotation_info)\n",
    "        self.save_json_annotation(json_data, f'annotation_{object_id}.json')\n",
    "    \n",
    "        annotation = f\"Speed: {formatted_speed} km/h, Category: {self.movement_category}\"\n",
    "        cv2.putText(frame, annotation, (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "    def create_json_annotation(self, object_id, speed, frame_info):\n",
    "        data = {\n",
    "            \"object_id\": object_id,\n",
    "            \"speed\": speed,\n",
    "            \"frame_info\": frame_info,\n",
    "        }\n",
    "        return json.dumps(data)\n",
    "\n",
    "    def save_json_annotation(self, json_data, filename):\n",
    "        with open(filename, 'w') as file:\n",
    "            file.write(json_data)\n",
    "     \n",
    "    # Release the video source when the object is destroyed\n",
    "    def release(self):\n",
    "        if self.vid.isOpened():\n",
    "            self.vid.release()\n",
    "        self.vid = None\n",
    "\n",
    "root = tk.Tk()\n",
    "app = ObjectDetectionGUI(root, \"Object Detection\")\n",
    "root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
